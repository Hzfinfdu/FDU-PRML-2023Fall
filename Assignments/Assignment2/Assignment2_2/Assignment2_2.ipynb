{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FDU PRML 2023 Fall Assignment 2.1\n",
    "\n",
    "Name: <your name>\n",
    "Student ID: <your student id>\n",
    "\n",
    "<font color='red'>**Deadline: 2023-11-20 23:59**</font>\n",
    "<font color='red'>**Overall score weight: 70/100**</font>\n",
    "\n",
    "In this semester, we are going to complete 3 assignments, each may contain **2-3 parts**. This is the second (and the last) part of the second assignment, in which we will get to implement our own Pytorch-like library.\n",
    "\n",
    "## 1. FDUNN: your toy torch-like deep learning library (40 points)\n",
    "\n",
    "In this assignment, you will fist implement your own torch-like deep learning library with `numpy`, named `fdunn`.\n",
    "\n",
    "PyTorch: [Link](https://pytorch.org/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup code, auto reload your .py file\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# numpy\n",
    "import numpy as np\n",
    "np.random.seed(233)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You have to impletement several standard deep neural network modules in the `./fdunn` folder:\n",
    "1.   linear/conv/pooling\n",
    "2.   activation\n",
    "3.   loss\n",
    "4.   optim\n",
    "5.   trainer\n",
    "\n",
    "We have written most of the code for you already, and you only need to fill in the most essential parts. We have also prepared several test cases for you to check if your code works correctly.\n",
    "\n",
    "Furthermore, you can also test the accuracy of your code by comparing its output with the output of sk-learn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from .fdunn import *\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Deep Learning with Image/Text Data (20 points)\n",
    "\n",
    "Use your fdunn lib to perform image classification on MNIST or CIFAR10 dataset.\n",
    "\n",
    "- MNIST: http://yann.lecun.com/exdb/mnist/\n",
    "- CIFAR10: https://www.cs.toronto.edu/~kriz/cifar.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Advanced Topics (10 points)\n",
    "\n",
    "You can try to implement some advanced topics in deep learning with our fdunn in this section.\n",
    "\n",
    "We will divide the topics into two categories: modules and optimization, with 5 points for each category.\n",
    "\n",
    "### 3.1 Modules\n",
    "\n",
    "Pick one of the following (trending or classic) topics and implement it with fdunn. Try to implement it and design a toy test case to show that your implementation is correct (say we can compare the forward and backward results with the results of corresponding Pytorch modules with the same weight).\n",
    "\n",
    "- Batch/Layer/Group Normalization (just one of them is fine)\n",
    "- A ReLU/GeLU/SiLU activation function (just one of them is fine)\n",
    "- A Gated Linear Unit (GLU)\n",
    "- An RNN cell\n",
    "- Or any other modules you are interested in\n",
    "\n",
    "\n",
    "### 3.2 Optimization\n",
    "\n",
    "Pick one of the following optimization methods and implement it with fdunn.\n",
    "\n",
    "- SGD with L2 regularization. (Try to repeat your experiment in Assignment 1.1 to see the same 'underregularization' to 'overregularization' phenomenon)\n",
    "- Adam (Does it converge faster than SGD in the last section?)\n",
    "- Or any other optimization methods you are interested in (I am far from an expert in optimization, so maybe you can teach me something new here. Say a second order method?)\n",
    "\n",
    "\n",
    "If you are not sure about what to do, We suggest you to implement the ReLU activation function and SGD with L2 regularization. They are foundamental and (relatively) easy to implement.\n",
    "\n",
    "Different methods do not vary in scores. So do not chase fancy methods unless you are quite interested in them.\n",
    "\n",
    "There are many ways to prove your implementation is correct, as long as they are convincing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
