{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDU PRML 2023 Fall Assignment 2.1\n",
    "\n",
    "Name: <your name>\n",
    "Student ID: <your student id>\n",
    "\n",
    "<font color='red'>**Deadline: 2023-10-30 23:59**</font>\n",
    "<font color='red'>**Overall score weight: 30/100**</font>\n",
    "\n",
    "In this semester, we are going to complete 3 assignments, each may contain **2-3 parts**. This is the first part of the second assignment, in which we will get to know about Pytorch. This assignment contains **little** explorations but **a bunch of** basic operations. So most of us will get full score in this assignment.\n",
    "\n",
    "Installing torch:\n",
    "```bash\n",
    "pip install torch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the instructions below and write your torch implementation in the following:\n",
    "\n",
    "## 1. Basic Operations of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_tensor = None  # TODO: assign a tensor of shape (3, 4) with all elements equal to 1.0\n",
    "\n",
    "my_second_tensor = None  # TODO: assign a random tensor of shape (3, 4) with all elements sampled from a standard normal distribution\n",
    "\n",
    "their_matrix_product = None  # TODO: compute the matrix product of my_first_tensor and the transpose of my_second_tensor (There are multiple ways to do this. Just pick one you like.)\n",
    "\n",
    "some_meaningless_concatenation = None  # TODO: concatenate my_first_tensor and my_second_tensor along the first dimension. (Maybe you should check the documentation of torch.cat)\n",
    "\n",
    "some_meaningless_stack = None  # TODO: stack 5 copies of my_first_tensor along a newly created dimension. (Maybe you should check the documentation of torch.stack)\n",
    "\n",
    "# What is the shape of some_meaningless_stack? Can you imagine the geometric interpretation of stacking 5 matrices of shape (3, 4) along the first dimension?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A simple logistic regression\n",
    "\n",
    "There are 4 core components in Pytorch training process: **model**, **loss function**, **optimizer** and **data loader**. In this part, we will implement a simple logistic regression model to illustrate them.\n",
    "\n",
    "### 2.1 Model and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear layer for logitstic regression\n",
    "\n",
    "class Linear(torch.nn.Module):\n",
    "\tdef __init__(self, input_dim, output_dim):\n",
    "\t\tsuper().__init__()\n",
    "\t\tpass\n",
    "\t\t# TODO: initialize the weight and bias of the linear layer.\n",
    "  \n",
    "\tdef forward(self, x):\n",
    "\t\tpass\n",
    "\t\t# TODO: implement the forward function of a linear layer.\n",
    "\n",
    "\n",
    "def loss_function(y_pred, y):\n",
    "    # TODO: implement the loss function of logistic regression.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data\n",
    "\n",
    "In real world, we usually have to deal with large-scale datasets. However, in this assignment, we will use synthetic data to illustrate the training process. The synthetic data is generated by the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random data for binary classification\n",
    "\n",
    "num_samples = 100\n",
    "num_features = 2\n",
    "\n",
    "x_0 = torch.randn(num_samples, num_features) + torch.tensor([2.0, 2.0])\n",
    "y_0 = torch.zeros(num_samples)\n",
    "\n",
    "x_1 = torch.randn(num_samples, num_features) + torch.tensor([-2.0, -2.0])\n",
    "y_1 = torch.ones(num_samples)\n",
    "\n",
    "x = torch.cat([x_0, x_1], dim=0)\n",
    "y = torch.cat([y_0, y_1], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset to feed into the model\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\tdef __init__(self, x, y):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t# TODO: implement the __getitem__ function.\n",
    "\t\tpass\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# TODO: implement the __len__ function.\n",
    "\t\tpass\n",
    "\n",
    "dataset = MyDataset(x, y)\n",
    "dataloder = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Linear(num_features, 1)\n",
    "\n",
    "optimizer = None  # TODO: initialize an optimizer of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together\n",
    "\n",
    "Since this is just a toy experiment, we do not need validation.\n",
    "\n",
    "In the following code, we expect to see the training loss decreasing to 0.001 or lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "for epoch in range(100):\n",
    "\tfor batch_x, batch_y in dataloder:\n",
    "\t\t# TODO: implement the training loop.\n",
    "\t\tpass\n",
    "  \n",
    "\tif epoch % 10 == 0:\n",
    "\t\tprint('epoch: {}, loss: {}'.format(epoch, loss.item()))\n",
    "  \n",
    "# save the model\n",
    "\n",
    "torch.save(my_model.state_dict(), 'my_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
